{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import tool\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Annotated\n",
    "from pydantic import BaseModel ,Field\n",
    "from lib.vector_db import VectorStoreManager\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\") is not None\n",
    "assert os.getenv(\"OPENAI_BASE_URL\") is not None\n",
    "assert os.getenv(\"TAVILY_API_KEY\") is not None\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3710db3",
   "metadata": {},
   "source": [
    "## Init VectorStoreManager and init Store\n",
    "\n",
    "- It using inside the chromadb and chroma_client lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594d0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = VectorStoreManager(name=\"chromadb\", \n",
    "                             openai_api_key=OPENAI_API_KEY, \n",
    "                             openai_base_url=OPENAI_BASE_URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06579e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameDocument(BaseModel):\n",
    "    \"\"\"\n",
    "    Game document containing information about a video game.\n",
    "    \n",
    "    Each element contains:\n",
    "        - Platform: like Game Boy, Playstation 5, Xbox 360...\n",
    "        - Name: Name of the Game\n",
    "        - YearOfRelease: Year when that game was released for that platform\n",
    "        - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "    Platform: Annotated[str, Field(description=\"Platform: like Game Boy, Playstation 5, Xbox 360...)\")]\n",
    "    Name: Annotated[str, Field(description=\"Name of the Game\")]\n",
    "    YearOfRelease: Annotated[int, Field(description=\"Year when that game was released for that platform\")]\n",
    "    Description: Annotated[str, Field(description=\"Additional details about the game\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_game (query:str, n_results: int = 3) -> List[GameDocument]:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB.\n",
    "    \n",
    "    Args:\n",
    "        query: A question about game industry.\n",
    "    \n",
    "    Returns:\n",
    "        List[GameDocument]: List of game documents matching the query.\n",
    "    \"\"\"\n",
    "    \n",
    "    chroma_client = manager.get_or_create_store(\"udaplay\")\n",
    "    \n",
    "    results = chroma_client.query(query_texts=query, n_results=n_results)\n",
    "\n",
    "    return [GameDocument(**meta) for meta in results['metadatas'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f337fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_all_games()->List[GameDocument]:\n",
    "\n",
    "    chroma_client = manager.get_or_create_store(\"udaplay\")\n",
    "\n",
    "    results = chroma_client.get()\n",
    "\n",
    "    return [GameDocument(**meta) for meta in results['metadatas'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d763846",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameEvaluation(BaseModel):\n",
    "    useful: Annotated[bool, Field(description=\"whether the documents are useful to answer the question\")]\n",
    "    description: Annotated[str, Field(description=\"description about the evaluation result\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def evaluate_retrieval(question:str, retrieved_docs:List[GameDocument])->GameEvaluation:\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question.\n",
    "    args: \n",
    "        - question: original question from user\n",
    "        - retrieved_docs: Full context of documents available to answer the question\n",
    "    The result includes:\n",
    "        - useful: whether the documents are useful to answer the question\n",
    "        - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "\n",
    "    llm = LLM( api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        \n",
    "        You are Professor Eval, a critical evaluation expert specializing \n",
    "        in information sufficiency analysis.\n",
    "\n",
    "        Your task: Assess whether the provided documents contain sufficient information to fully and \n",
    "        accurately answer the user's question.\n",
    "\n",
    "        Evaluation Guidelines:\n",
    "            - Be strict and objective - base your judgment solely on the provided documents\n",
    "            - Check if all necessary facts, details, and context are present\n",
    "            - Identify any gaps, ambiguities, or missing information\n",
    "            - Do not assume information beyond what is explicitly provided\n",
    "\n",
    "        Set `useful`:\n",
    "            - True: Only if the documents contain complete and clear information to answer the question fully\n",
    "            - False: If any critical information is missing, unclear, insufficient, unclear or requires assumptions\n",
    "\n",
    "        Provide `description`:\n",
    "            - A concise 2-3 sentence explanation of your evaluation\n",
    "            - State what is present or what is missing\n",
    "            - Be direct and specific\n",
    "\n",
    "        When in doubt, mark as False. Quality over leniency.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "\n",
    "        USER QUESTION:\n",
    "        {question}\n",
    "\n",
    "        RETRIEVED DOCUMENTS:\n",
    "        {retrieved_docs}\n",
    "\n",
    "        TASK: \n",
    "        Evaluate whether the retrieved documents contain sufficient information to fully answer the user question.\n",
    "    \"\"\"\n",
    "\n",
    "    messages=[\n",
    "        SystemMessage(content=system_prompt),\n",
    "        UserMessage(content=user_prompt)\n",
    "    ]\n",
    "\n",
    "    return llm.invoke( input=messages, response_format=GameEvaluation).content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcb7a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult(BaseModel):\n",
    "    answer: Annotated[str, Field(description=\"web search answer to the query\")]\n",
    "    results: Annotated[List[str], Field(description=\"web search results as list\")]\n",
    "    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat(), description=\"timestamp\")\n",
    "    query: Annotated[str, Field(description=\"initial query\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def game_web_search(question: str) -> SearchResult:\n",
    "    \"\"\"\n",
    "     Semantic search: Finds most results in the vector DB\n",
    "    args:\n",
    "        - question: a question about game industry. \n",
    "    \"\"\"\n",
    "    search_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
    "\n",
    "    results = search_client.search(query=question, \n",
    "                                   search_depth=\"advanced\",\n",
    "                                   include_answer=True,\n",
    "                                   include_favicon=False,\n",
    "                                   include_images=False,\n",
    "                                   include_raw_content=False\n",
    "                                   )\n",
    "    \n",
    "    return SearchResult(answer=results.get(\"answer\", \"\"),\n",
    "                results=results.get(\"results\", []),\n",
    "                query=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "\n",
    "You are a knowledgeable video game expert assistant specializing in providing accurate \n",
    "and comprehensive information about computer games.\n",
    "\n",
    "Your capabilities:\n",
    "- Search and retrieve detailed game information from a knowledge base\n",
    "- Evaluate whether retrieved information is sufficient to answer questions\n",
    "- Perform web searches for additional or up-to-date game information when needed\n",
    "\n",
    "Your approach:\n",
    "1. Always start by retrieving information from the knowledge base\n",
    "2. Critically evaluate if the retrieved information fully answers the user's question\n",
    "3. If information is insufficient or outdated, perform a web search to supplement your answer\n",
    "4. Provide clear, accurate, and well-structured responses\n",
    "5. Cite your sources when providing specific facts or data\n",
    "\n",
    "Guidelines:\n",
    "- Be precise and factual - avoid speculation\n",
    "- If information is unavailable, clearly state this\n",
    "- For questions about recent games or updates, prioritize web search results\n",
    "- Combine multiple sources when needed for comprehensive answers\n",
    "- Keep responses concise but informative\n",
    "\n",
    "Your goal is to provide the most accurate and helpful game information possible.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "gameAgent = Agent(\n",
    "    model_name=\"gpt-4o\",\n",
    "    tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    "    instructions=instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_conversation(messages):\n",
    "    for i, msg in enumerate(messages, 1):\n",
    "        role = msg.role.upper()\n",
    "        \n",
    "        if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "            tool_names = [tc.function.name for tc in msg.tool_calls]\n",
    "            print(f\"[{i}] ðŸ¤– {role}: Tool calls â†’ {', '.join(tool_names)}\")\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            content_preview = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "            print(f\"[{i}] ðŸ”§ TOOL ({msg.name}): {content_preview}\")\n",
    "        elif isinstance(msg, SystemMessage):\n",
    "            print(f\"[{i}] âš™ï¸  {role}: [System instructions]\")\n",
    "        else:\n",
    "            print(f\"[{i}] {'ðŸ‘¤' if role == 'USER' else 'ðŸ¤–'} {role}: {msg.content}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73676268",
   "metadata": {},
   "source": [
    "### First Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a47b64d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "[1] âš™ï¸  SYSTEM: [System instructions]\n",
      "\n",
      "[2] ðŸ‘¤ USER: When PokÃ©mon Gold and Silver was released?\n",
      "\n",
      "[3] ðŸ¤– ASSISTANT: Tool calls â†’ retrieve_game\n",
      "\n",
      "[4] ðŸ”§ TOOL (retrieve_game): \"[GameDocument(Platform='Game Boy Color', Name='Pok\\u00e9mon Gold and Silver', YearOfRelease=1999, D...\n",
      "\n",
      "[5] ðŸ¤– ASSISTANT: Tool calls â†’ evaluate_retrieval\n",
      "\n",
      "[6] ðŸ”§ TOOL (evaluate_retrieval): \"{\\\"useful\\\":true,\\\"description\\\":\\\"The documents clearly state that Pok\\u00e9mon Gold and Silver we...\n",
      "\n",
      "[7] ðŸ¤– ASSISTANT: PokÃ©mon Gold and Silver were released in 1999 for the Game Boy Color. These games are part of the second generation of PokÃ©mon games, introducing new regions, PokÃ©mon, and gameplay mechanics.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "query = \"When PokÃ©mon Gold and Silver was released?\"\n",
    "\n",
    "response = gameAgent.invoke(query=query)\n",
    "\n",
    "print(print_conversation(response.get_final_state()[\"messages\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac44c14",
   "metadata": {},
   "source": [
    "### Second Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1899c418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "[1] âš™ï¸  SYSTEM: [System instructions]\n",
      "\n",
      "[2] ðŸ‘¤ USER: When PokÃ©mon Gold and Silver was released?\n",
      "\n",
      "[3] ðŸ¤– ASSISTANT: Tool calls â†’ retrieve_game\n",
      "\n",
      "[4] ðŸ”§ TOOL (retrieve_game): \"[GameDocument(Platform='Game Boy Color', Name='Pok\\u00e9mon Gold and Silver', YearOfRelease=1999, D...\n",
      "\n",
      "[5] ðŸ¤– ASSISTANT: Tool calls â†’ evaluate_retrieval\n",
      "\n",
      "[6] ðŸ”§ TOOL (evaluate_retrieval): \"{\\\"useful\\\":true,\\\"description\\\":\\\"The documents clearly state that Pok\\u00e9mon Gold and Silver we...\n",
      "\n",
      "[7] ðŸ¤– ASSISTANT: PokÃ©mon Gold and Silver were released in 1999 for the Game Boy Color. These games are part of the second generation of PokÃ©mon games, introducing new regions, PokÃ©mon, and gameplay mechanics.\n",
      "\n",
      "[8] ðŸ‘¤ USER: Which one was the first 3D platformer Mario game?\n",
      "\n",
      "[9] ðŸ¤– ASSISTANT: Tool calls â†’ retrieve_game\n",
      "\n",
      "[10] ðŸ”§ TOOL (retrieve_game): \"[GameDocument(Platform='Nintendo 64', Name='Super Mario 64', YearOfRelease=1996, Description=\\\"A gr...\n",
      "\n",
      "[11] ðŸ¤– ASSISTANT: Tool calls â†’ evaluate_retrieval\n",
      "\n",
      "[12] ðŸ”§ TOOL (evaluate_retrieval): \"{\\\"useful\\\":true,\\\"description\\\":\\\"The documents clearly state that 'Super Mario 64' for the Ninten...\n",
      "\n",
      "[13] ðŸ¤– ASSISTANT: The first 3D platformer Mario game was \"Super Mario 64,\" released in 1996 for the Nintendo 64. It was a groundbreaking game that set new standards for the 3D platforming genre.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "query = \"Which one was the first 3D platformer Mario game?\"\n",
    "\n",
    "response = gameAgent.invoke(query=query)\n",
    "\n",
    "print(print_conversation(response.get_final_state()[\"messages\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3061b70",
   "metadata": {},
   "source": [
    "### Third Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ceae87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for SearchResult\nresults.0\n  Input should be a valid string [type=string_type, input_value={'url': 'https://www.psu....39, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nresults.1\n  Input should be a valid string [type=string_type, input_value={'url': 'https://store.pl...05, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nresults.2\n  Input should be a valid string [type=string_type, input_value={'url': 'https://gamefaqs...48, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nresults.3\n  Input should be a valid string [type=string_type, input_value={'url': 'https://www.play...22, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nresults.4\n  Input should be a valid string [type=string_type, input_value={'url': 'https://www.game...64, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mWas Mortal Kombat X realeased for Playstation 5?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mgameAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(print_conversation(response.get_final_state()[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/agentic-ai-nd/Course-03/project/starter/lib/agents.py:176\u001b[39m, in \u001b[36mAgent.invoke\u001b[39m\u001b[34m(self, query, session_id)\u001b[39m\n\u001b[32m    166\u001b[39m         previous_messages = last_state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    168\u001b[39m initial_state: AgentState = {\n\u001b[32m    169\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muser_query\u001b[39m\u001b[33m\"\u001b[39m: query,\n\u001b[32m    170\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.instructions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    173\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m: session_id,\n\u001b[32m    174\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m run_object = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# Store the complete run object in memory\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;28mself\u001b[39m.memory.add(run_object, session_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/agentic-ai-nd/Course-03/project/starter/lib/state_machine.py:231\u001b[39m, in \u001b[36mStateMachine.run\u001b[39m\u001b[34m(self, state, resource)\u001b[39m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Replace state entirely\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m state = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, EntryPoint):\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[StateMachine] Starting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_step_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/agentic-ai-nd/Course-03/project/starter/lib/state_machine.py:40\u001b[39m, in \u001b[36mStep.run\u001b[39m\u001b[34m(self, state, state_schema, resource)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: StateSchema, state_schema: Type[StateSchema], resource: Resource=\u001b[38;5;28;01mNone\u001b[39;00m) -> StateSchema:\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# Call logic function with appropriate number of arguments\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.logic_params_count == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.logic_params_count == \u001b[32m2\u001b[39m:\n\u001b[32m     42\u001b[39m         result = \u001b[38;5;28mself\u001b[39m.logic(state, resource)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/agentic-ai-nd/Course-03/project/starter/lib/agents.py:100\u001b[39m, in \u001b[36mAgent._tool_step\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m     98\u001b[39m tool = \u001b[38;5;28mnext\u001b[39m((t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tools \u001b[38;5;28;01mif\u001b[39;00m t.name == function_name), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     result = \u001b[38;5;28mstr\u001b[39m(\u001b[43mtool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunction_args\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    101\u001b[39m     tool_message = ToolMessage(\n\u001b[32m    102\u001b[39m         content=json.dumps(result), \n\u001b[32m    103\u001b[39m         tool_call_id=tool_call_id, \n\u001b[32m    104\u001b[39m         name=function_name, \n\u001b[32m    105\u001b[39m     )\n\u001b[32m    106\u001b[39m     tool_messages.append(tool_message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/agentic-ai-nd/Course-03/project/starter/lib/tooling.py:106\u001b[39m, in \u001b[36mTool.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mgame_web_search\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m      8\u001b[39m search_client = TavilyClient(api_key=TAVILY_API_KEY)\n\u001b[32m     10\u001b[39m results = search_client.search(query=question, \n\u001b[32m     11\u001b[39m                                search_depth=\u001b[33m\"\u001b[39m\u001b[33madvanced\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m                                include_answer=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m                                include_raw_content=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     16\u001b[39m                                )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSearchResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresults\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Work/agentic-ai-nd/py-3-13-9/lib/python3.13/site-packages/pydantic/main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 5 validation errors for SearchResult\nresults.0\n  Input should be a valid string [type=string_type, input_value={'url': 'https://www.psu....39, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nresults.1\n  Input should be a valid string [type=string_type, input_value={'url': 'https://store.pl...05, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nresults.2\n  Input should be a valid string [type=string_type, input_value={'url': 'https://gamefaqs...48, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nresults.3\n  Input should be a valid string [type=string_type, input_value={'url': 'https://www.play...22, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\nresults.4\n  Input should be a valid string [type=string_type, input_value={'url': 'https://www.game...64, 'raw_content': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type"
     ]
    }
   ],
   "source": [
    "query = \"Was Mortal Kombat X realeased for Playstation 5?\"\n",
    "\n",
    "response = gameAgent.invoke(query=query)\n",
    "\n",
    "print(print_conversation(response.get_final_state()[\"messages\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3-13-9 (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
